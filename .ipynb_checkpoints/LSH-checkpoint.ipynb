{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adefb52d-d7da-47e4-8f54-3ae4cfa9f5c1",
   "metadata": {},
   "source": [
    "# exemple faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baadd54d-2922-4f59-a26c-3f380e560f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest neighbors: [[  100 27433   950 11812 27635 28573 31299 33109 24018  8661]]\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Generate random 256-D vectors\n",
    "N = 100000  # Number of vectors\n",
    "D = 256  # Dimension\n",
    "data = np.random.random((N, D)).astype('float32')\n",
    "\n",
    "# Create an LSH index\n",
    "num_bits = 16  # Number of bits for hashing\n",
    "index = faiss.IndexLSH(D, num_bits)\n",
    "# https://github.com/facebookresearch/faiss/wiki/Faiss-indexes/1f721de164ae7950c65914d2dde0865312584a36\n",
    "\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(data)\n",
    "\n",
    "# Query\n",
    "#query = np.random.random((1, D)).astype('float32')\n",
    "query = np.expand_dims(data[100], 0)\n",
    "D, I = index.search(query, 10)  # Find top-10 nearest neighbors\n",
    "\n",
    "print(\"Nearest neighbors:\", I)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c890aad2-0e49-4729-8253-fed969356f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "feat_dists = cdist(query, data, metric='cosine').reshape(-1)\n",
    "min_dist, nearest_idx = np.min(feat_dists), np.argmin(feat_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d461e103-7eea-4ddc-a162-968e5ff347f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.23543808, 0.24439688, 0.25769359, ..., 0.24738973, 0.29674815,\n",
       "        0.24196164])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[  cdist(np.expand_dims(data[x], 0)[0], data, metric='cosine').reshape(-1) for x in I]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a750a12-d047-4e77-92c3-2176814bcdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([ np.expand_dims(data[x], 0) for x in I][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e435d3-1b4e-424e-8ae3-0b06f0c416e7",
   "metadata": {},
   "source": [
    "# faiss sur kitti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f52d02ab-e37d-4679-a848-1a23bdbd478a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kitti dataset\n"
     ]
    },
    {
     "ename": "<class 'NameError'>",
     "evalue": "name 'padded_string' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m query_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_queries):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m#input_data = data_collator(torch.utils.data.Subset(eval_subset,range(query_idx, query_idx+1)))\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#ids = input_data['ids'][0]\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m#padded_string = str(query_idx).zfill(6)\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(padded_string)\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m#import pdb; pdb.set_trace()                \u001b[39;00m\n\u001b[1;32m     21\u001b[0m     log_desc \u001b[38;5;241m=\u001b[39m sequence_path \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/logg_desc/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m padded_string \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'padded_string' is not defined"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "\n",
    "eval_seq = 6\n",
    "log3dnet_dir=os.getenv('LOG3DNET_DIR')\n",
    "## ==== Kitti =====\n",
    "print(\"kitti dataset\")\n",
    "#kitti_dir = os.getenv('WORKSF') + '/datas/datasets/'\n",
    "kitti_dir = '/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/'\n",
    "eval_seq = '%02d' % eval_seq\n",
    "sequence_path = kitti_dir + 'sequences/' + eval_seq + '/'\n",
    "num_queries = 1101\n",
    "embeddings = []\n",
    "for query_idx in range(num_queries):\n",
    "    #input_data = data_collator(torch.utils.data.Subset(eval_subset,range(query_idx, query_idx+1)))\n",
    "    #ids = input_data['ids'][0]\n",
    "    padded_string = str(query_idx).zfill(6)\n",
    "    print(padded_string)\n",
    "    #import pdb; pdb.set_trace()                \n",
    "    log_desc = sequence_path + \"/logg_desc/\" + padded_string + '.pt'\n",
    "\n",
    "    xx = torch.load(log_desc)\n",
    "    #xx1 = torch.load(fname)\n",
    "    embeddings.append(xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070848c9-26fb-4aca-8313-66f2df5f05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "\n",
    "# Generate random 256-D vectors\n",
    "N = 100000  # Number of vectors\n",
    "D = 256  # Dimension\n",
    "data = \n",
    "\n",
    "# Create an LSH index\n",
    "num_bits = 16  # Number of bits for hashing\n",
    "index = faiss.IndexLSH(D, num_bits)\n",
    "index = faiss.IndexLSH(D, num_bits)\n",
    "# https://github.com/facebookresearch/faiss/wiki/Faiss-indexes/1f721de164ae7950c65914d2dde0865312584a36\n",
    "\n",
    "\n",
    "# Add vectors to the index\n",
    "index.add(data)\n",
    "\n",
    "# Query\n",
    "#query = np.random.random((1, D)).astype('float32')\n",
    "query = np.expand_dims(data[1], 0)\n",
    "D, I = index.search(query, 10)  # Find top-10 nearest neighbors\n",
    "\n",
    "print(\"Nearest neighbors:\", I)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-gpu-1.10.1_py3.9.7",
   "language": "python",
   "name": "module-conda-env-pytorch-gpu-1.10.1_py3.9.7"
  },
  "language_info": {
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
