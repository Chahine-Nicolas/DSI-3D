{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3684d975-8cb6-4ea9-afd5-a52c2784a882",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "list_seq = [0, 2, 5, 6, 7, 8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65c3ffdb-cca2-40d5-9264-7728380bde1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.8481e-02,  8.6601e-02, -7.0134e-03,  1.6344e-02, -2.3149e-02,\n",
       "         1.0376e-01,  1.2083e-01,  9.1092e-02, -4.5692e-03,  1.6834e-02,\n",
       "         4.5644e-04, -1.3772e-02,  4.8798e-02,  1.1736e-01, -1.6887e-04,\n",
       "         1.3325e-02,  8.6601e-02,  1.1204e-01,  4.3936e-02,  3.5872e-02,\n",
       "         1.2838e-01, -3.0842e-02,  6.5218e-02,  2.5790e-02,  1.7394e-02,\n",
       "         1.6041e-02, -2.4132e-03,  5.9090e-02, -4.8816e-03, -1.3363e-02,\n",
       "        -2.1906e-02,  2.5252e-02, -7.0134e-03,  4.3936e-02,  1.4819e-01,\n",
       "         1.2371e-01,  6.6776e-02, -1.2201e-02,  2.7130e-02,  1.6900e-02,\n",
       "        -1.7000e-02,  4.0488e-03,  5.2270e-03,  1.5511e-02,  2.9914e-02,\n",
       "         4.7399e-02,  2.5026e-02,  4.5284e-02,  1.6344e-02,  3.5872e-02,\n",
       "         1.2371e-01,  9.4416e-02, -4.7252e-03,  2.3990e-02,  2.7812e-02,\n",
       "        -1.1348e-02,  4.7821e-02,  3.9755e-02,  2.0122e-02,  5.1059e-03,\n",
       "        -9.6295e-03, -5.5556e-03,  3.8622e-02, -2.9109e-03, -2.3149e-02,\n",
       "         1.2838e-01,  6.6776e-02, -4.7252e-03,  1.5779e-01,  3.6481e-02,\n",
       "         7.5891e-02, -2.5318e-02,  5.6654e-02,  4.3216e-02,  3.1825e-02,\n",
       "         9.8949e-04,  3.8748e-02,  2.9488e-02,  1.0095e-02,  2.2487e-02,\n",
       "         1.0376e-01, -3.0842e-02, -1.2201e-02,  2.3990e-02,  3.6481e-02,\n",
       "         1.2582e-01,  1.5806e-01,  8.9134e-02, -2.1486e-02,  2.3368e-02,\n",
       "        -6.8915e-03,  2.9786e-02, -8.6001e-03,  1.4989e-01, -2.9962e-02,\n",
       "        -1.1931e-03,  1.2083e-01,  6.5218e-02,  2.7130e-02,  2.7812e-02,\n",
       "         7.5891e-02,  1.5806e-01,  7.2198e-02,  1.1328e-01,  1.3082e-01,\n",
       "        -1.7888e-02, -7.2563e-03, -2.7165e-03,  3.3464e-03,  1.4331e-01,\n",
       "         1.7939e-01, -2.3893e-02,  9.1092e-02,  2.5790e-02,  1.6900e-02,\n",
       "        -1.1348e-02, -2.5318e-02,  8.9134e-02,  1.1328e-01,  5.3256e-02,\n",
       "        -4.1526e-02,  1.5286e-02,  1.4855e-02,  2.1110e-02, -5.7299e-03,\n",
       "         1.0600e-01,  4.5452e-02,  1.0054e-02, -4.5692e-03,  1.7394e-02,\n",
       "        -1.7000e-02,  4.7821e-02,  5.6654e-02, -2.1486e-02,  1.3082e-01,\n",
       "        -4.1526e-02,  1.7547e-01, -2.6279e-02,  2.6440e-02,  3.4396e-02,\n",
       "         1.1359e-01,  3.4292e-02,  1.5185e-01,  3.4758e-03,  1.6834e-02,\n",
       "         1.6041e-02,  4.0488e-03,  3.9755e-02,  4.3216e-02,  2.3368e-02,\n",
       "        -1.7888e-02,  1.5286e-02, -2.6279e-02,  1.6773e-01,  1.2341e-02,\n",
       "         2.4050e-02,  7.2263e-02,  1.6922e-02,  5.1469e-02,  3.5263e-02,\n",
       "         4.5644e-04, -2.4132e-03,  5.2270e-03,  2.0122e-02,  3.1825e-02,\n",
       "        -6.8915e-03, -7.2563e-03,  1.4855e-02,  2.6440e-02,  1.2341e-02,\n",
       "         6.2500e-02,  1.9299e-02,  1.4436e-03,  5.1475e-02,  1.2331e-02,\n",
       "         2.9032e-03, -1.3772e-02,  5.9090e-02,  1.5511e-02,  5.1059e-03,\n",
       "         9.8949e-04,  2.9786e-02, -2.7165e-03,  2.1110e-02,  3.4396e-02,\n",
       "         2.4050e-02,  1.9299e-02,  1.4135e-01,  6.9112e-03,  1.5204e-02,\n",
       "         5.9929e-03,  2.0210e-02,  4.8798e-02, -4.8816e-03,  2.9914e-02,\n",
       "        -9.6295e-03,  3.8748e-02, -8.6001e-03,  3.3464e-03, -5.7299e-03,\n",
       "         1.1359e-01,  7.2263e-02,  1.4436e-03,  6.9112e-03,  8.9714e-02,\n",
       "         2.4336e-02,  1.2227e-02,  1.2718e-03,  1.1736e-01, -1.3363e-02,\n",
       "         4.7399e-02, -5.5556e-03,  2.9488e-02,  1.4989e-01,  1.4331e-01,\n",
       "         1.0600e-01,  3.4292e-02,  1.6922e-02,  5.1475e-02,  1.5204e-02,\n",
       "         2.4336e-02,  1.3223e-01, -4.4350e-02,  7.4356e-02, -1.6887e-04,\n",
       "        -2.1906e-02,  2.5026e-02,  3.8622e-02,  1.0095e-02, -2.9962e-02,\n",
       "         1.7939e-01,  4.5452e-02,  1.5185e-01,  5.1469e-02,  1.2331e-02,\n",
       "         5.9929e-03,  1.2227e-02, -4.4350e-02,  1.9744e-01,  6.5476e-02,\n",
       "         1.3325e-02,  2.5252e-02,  4.5284e-02, -2.9109e-03,  2.2487e-02,\n",
       "        -1.1931e-03, -2.3893e-02,  1.0054e-02,  3.4758e-03,  3.5263e-02,\n",
       "         2.9032e-03,  2.0210e-02,  1.2718e-03,  7.4356e-02,  6.5476e-02,\n",
       "         1.4629e-01], device='cuda:0', dtype=torch.float64, requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#test_feature_0 = torch.load(\"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/02/logg_desc/003459.pt\")\n",
    "\n",
    "\n",
    "test_feature = torch.load(\"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/06/logg_desc/000000.pt\")\n",
    "test_feature\n",
    "#print(test_feature_0, test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2343a68c-25d0-4af5-ba41-78b0a340b616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.7103e-09,  3.0180e-10, -9.2600e-10, -4.2619e-09,  8.6600e-09,\n",
       "        -1.1683e-08, -1.0865e-08,  1.3960e-08, -8.6064e-09,  1.0560e-08,\n",
       "        -1.3092e-08,  2.1603e-09,  1.1182e-10,  1.3087e-08,  3.6956e-09,\n",
       "        -1.8678e-08,  3.0180e-10,  5.5188e-09,  1.1773e-08,  9.7007e-10,\n",
       "        -9.6609e-09,  1.6375e-08,  7.3262e-10, -6.9594e-09,  2.8876e-09,\n",
       "         2.5420e-09,  1.4092e-08, -1.4332e-08,  1.2631e-08,  3.5528e-09,\n",
       "        -7.4872e-09, -5.1528e-09, -9.2600e-10,  1.1773e-08, -4.0448e-08,\n",
       "         5.4097e-09,  1.5302e-08, -5.1972e-09, -1.4068e-09,  9.1546e-09,\n",
       "         1.2987e-08, -2.3336e-08, -2.1374e-09,  2.6142e-08, -3.7456e-09,\n",
       "        -7.0301e-09,  1.3610e-08, -6.3777e-09, -4.2619e-09,  9.7007e-10,\n",
       "         5.4097e-09,  1.9315e-08, -2.2368e-08, -1.4841e-08,  9.2968e-09,\n",
       "         1.1226e-08, -1.4603e-08,  7.6444e-09,  2.4047e-09,  7.1063e-09,\n",
       "        -2.6163e-10,  1.2561e-09, -2.9712e-09, -9.8746e-09,  8.6600e-09,\n",
       "        -9.6609e-09,  1.5302e-08, -2.2368e-08,  1.5372e-08, -8.2871e-09,\n",
       "         3.7905e-10,  4.0696e-08, -7.7610e-09,  2.3867e-08, -2.2859e-08,\n",
       "        -2.3883e-08,  2.5904e-09,  1.4835e-08,  1.2719e-09,  2.3038e-09,\n",
       "        -1.1683e-08,  1.6375e-08, -5.1972e-09, -1.4841e-08, -8.2871e-09,\n",
       "         1.3481e-08, -2.1121e-08,  9.7647e-09,  1.6978e-08, -1.2588e-08,\n",
       "         1.2774e-08,  3.3837e-09,  1.9725e-08,  5.6553e-09,  8.4828e-09,\n",
       "        -2.3701e-09, -1.0865e-08,  7.3262e-10, -1.4068e-09,  9.2968e-09,\n",
       "         3.7905e-10, -2.1121e-08, -2.0733e-08,  3.7862e-08,  7.3436e-10,\n",
       "        -2.7436e-08,  6.8643e-09,  9.9510e-09, -7.5238e-09, -6.7721e-09,\n",
       "        -2.0439e-09,  8.2538e-10,  1.3960e-08, -6.9594e-09,  9.1546e-09,\n",
       "         1.1226e-08,  4.0696e-08,  9.7647e-09,  3.7862e-08, -7.6606e-08,\n",
       "        -1.2356e-08,  3.9891e-09, -4.8182e-09, -5.7233e-09,  2.6327e-09,\n",
       "         8.2559e-09, -5.7609e-10,  2.8134e-09, -8.6064e-09,  2.8876e-09,\n",
       "         1.2987e-08, -1.4603e-08, -7.7610e-09,  1.6978e-08,  7.3436e-10,\n",
       "        -1.2356e-08, -1.6364e-08, -3.3051e-08,  7.2679e-09, -1.2999e-09,\n",
       "        -5.9633e-09,  2.3223e-08,  7.4268e-10,  9.1905e-09,  1.0560e-08,\n",
       "         2.5420e-09, -2.3336e-08,  7.6444e-09,  2.3867e-08, -1.2588e-08,\n",
       "        -2.7436e-08,  3.9891e-09, -3.3051e-08,  2.9533e-08, -2.1275e-08,\n",
       "         1.2239e-08, -5.0577e-09, -2.2408e-09,  8.6074e-09,  2.1365e-09,\n",
       "        -1.3092e-08,  1.4092e-08, -2.1374e-09,  2.4047e-09, -2.2859e-08,\n",
       "         1.2774e-08,  6.8643e-09, -4.8182e-09,  7.2679e-09, -2.1275e-08,\n",
       "         2.0707e-08, -1.2190e-09, -4.5064e-09,  5.8817e-09, -1.1953e-09,\n",
       "         3.2992e-09,  2.1603e-09, -1.4332e-08,  2.6142e-08,  7.1063e-09,\n",
       "        -2.3883e-08,  3.3837e-09,  9.9510e-09, -5.7233e-09, -1.2999e-09,\n",
       "         1.2239e-08, -1.2190e-09, -1.9942e-08, -3.0843e-09, -2.4269e-09,\n",
       "        -8.9867e-09,  2.4466e-08,  1.1182e-10,  1.2631e-08, -3.7456e-09,\n",
       "        -2.6163e-10,  2.5904e-09,  1.9725e-08, -7.5238e-09,  2.6327e-09,\n",
       "        -5.9633e-09, -5.0577e-09, -4.5064e-09, -3.0843e-09, -4.8304e-09,\n",
       "         6.5146e-09, -4.2195e-09,  1.1257e-08,  1.3087e-08,  3.5528e-09,\n",
       "        -7.0301e-09,  1.2561e-09,  1.4835e-08,  5.6553e-09, -6.7721e-09,\n",
       "         8.2559e-09,  2.3223e-08, -2.2408e-09,  5.8817e-09, -2.4269e-09,\n",
       "         6.5146e-09, -6.9819e-08, -3.0745e-09,  8.2534e-09,  3.6956e-09,\n",
       "        -7.4872e-09,  1.3610e-08, -2.9712e-09,  1.2719e-09,  8.4828e-09,\n",
       "        -2.0439e-09, -5.7609e-10,  7.4268e-10,  8.6074e-09, -1.1953e-09,\n",
       "        -8.9867e-09, -4.2195e-09, -3.0745e-09,  7.6764e-09,  1.1840e-09,\n",
       "        -1.8678e-08, -5.1528e-09, -6.3777e-09, -9.8746e-09,  2.3038e-09,\n",
       "        -2.3701e-09,  8.2538e-10,  2.8134e-09,  9.1905e-09,  2.1365e-09,\n",
       "         3.2992e-09,  2.4466e-08,  1.1257e-08,  8.2534e-09,  1.1840e-09,\n",
       "        -3.6262e-09], device='cuda:0', dtype=torch.float64,\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_feature_0 - test_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "952989b0-ba7c-4a96-af67-e4fe47b00bb5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = open(\"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/22/hilbert.json\",) \n",
    "data = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for i in range (len(data)):\n",
    "\n",
    "    if int(i) < 4541:\n",
    "        eval_seq = '00'\n",
    "        new_number = '%02d' %i  +'.bin'\n",
    "        print(eval_seq, new_number)\n",
    "    elif 4541 <= int(i) < 9202:\n",
    "        eval_seq = '02'\n",
    "        new_number = '%02d' % (int(i) - 4541)  +'.bin'\n",
    "        print(eval_seq, new_number)\n",
    "    elif 9203 <= int(i) < 11964:\n",
    "        eval_seq = '05'\n",
    "        new_number = str( int(i) - 9203 ) +'.bin'\n",
    "        print(eval_seq, new_number)\n",
    "    elif 11965 <= int(i) < 13066:\n",
    "        eval_seq = '06'\n",
    "        new_number = str( int(i) - 11965 ) +'.bin'\n",
    "        print(eval_seq, new_number)\n",
    "    elif 13067 <= int(i) < 14168:\n",
    "        eval_seq = '07'\n",
    "        new_number = str( int(i) - 13067 ) +'.bin'\n",
    "        print(eval_seq, new_number)\n",
    "    elif 14169 <= int(i):\n",
    "        eval_seq = '08'\n",
    "        new_number = str( int(i) - 14169) +'.bin'\n",
    "        print(eval_seq, new_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4f7e0-f510-4dda-a4dc-43523267b1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "list_seq = [0, 2, 5, 6, 7, 8] \n",
    "root_path = \"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/\"\n",
    "\n",
    "\n",
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, list_seq, data, root_path):\n",
    "        self.samples = []\n",
    "        self.labels = []\n",
    "        self.seq_to_idx = {seq: i for i, seq in enumerate(list_seq)}  # converti 0,2,5 en 0,1,2..\n",
    "\n",
    "        for seq in list_seq:\n",
    "            seq_str = f\"{seq:02d}\"\n",
    "            sequence_path = os.path.join(root_path, seq_str, \"logg_desc\")\n",
    "\n",
    "            for j in range(len(data[seq_str])):\n",
    "                file_path = os.path.join(sequence_path, f\"{j:06d}.pt\")\n",
    "\n",
    "                if j % 5 == 0:\n",
    "                    continue\n",
    "                \n",
    "                if os.path.exists(file_path):\n",
    "                    vec = torch.load(file_path).to(torch.float32) \n",
    "                    self.samples.append(vec)\n",
    "                    self.labels.append(self.seq_to_idx[seq])\n",
    "                       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.samples[idx], self.labels[idx]\n",
    "\n",
    "\n",
    "class ExpertClassifier(nn.Module):\n",
    "    def __init__(self, input_dim=256, num_experts=len(list_seq)):\n",
    "        super(ExpertClassifier, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_experts)  # Output: one neuron per expert\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "def predict_expert(model, feature_vector, device):\n",
    "    with torch.no_grad():\n",
    "        feature_vector = feature_vector.to(device).unsqueeze(0)  # Add batch dimension\n",
    "        output = model(feature_vector)\n",
    "        predicted_expert_idx = torch.argmax(output).item()\n",
    "\n",
    "        # proba\n",
    "        m = nn.Softmax(dim=1)\n",
    "        prob_seq = m(output)\n",
    "\n",
    "    return list_seq[predicted_expert_idx], output[0][predicted_expert_idx], prob_seq[0][predicted_expert_idx] \n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    with open(\"/lustre/fswork/projects/rech/dki/ujo91el/code/these_place_reco/LoGG3D-Net/config/kitti_tuples/is_revisit_D-3_T-30.json\") as f:\n",
    "        data = json.load(f)\n",
    "    root_path = \"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/\"\n",
    "    print(\"Load dataset\")\n",
    "    dataset = SequenceDataset(list_seq, data, root_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    device=\"cuda\"\n",
    "    # load gate\n",
    "\n",
    "    #from train_relu import ExpertClassifier\n",
    "\n",
    "    # Define the model with the same architecture\n",
    "    gate_model = ExpertClassifier()\n",
    "    \n",
    "    # Load the saved weights\n",
    "    print(\"load \",\"expert_router.pth\")\n",
    "    gate_model.load_state_dict(torch.load(\"expert_router.pth\"))\n",
    "    gate_model.to(device=\"cuda\")\n",
    "    gate_model.eval()  # Set the model to evaluation mode\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "    #import pdb; pdb.set_trace()\n",
    "    \n",
    "    seq_str =  cfg['DATA_CONFIG']['SEQ']\n",
    "    root_path = \"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/\"\n",
    "    desc_path = os.path.join(root_path, seq_str, \"logg_desc\")\n",
    "    file_path = os.path.join(desc_path, f\"{query_idx:06d}.pt\")\n",
    "    \n",
    "    test_feature = torch.load(file_path).to(torch.float32)\n",
    "\n",
    "    best_expert, expert_seq, score, prob = predict_expert(gate_model, test_feature, 'cuda')\n",
    "    print(file_path)\n",
    "    print(f\"Predicted expert: {best_expert}, Expected expert: {int(seq_str)}, Score: {score}, proba: {prob} \")\n",
    "    \"\"\"\n",
    "\n",
    "    # evaluation\n",
    "    print(\"start evaluation\")\n",
    "    seq_to_idx = {seq: i for i, seq in enumerate(list_seq)}\n",
    "    hit, num = 0, 0\n",
    "    seen_proba = []\n",
    "    for seq in list_seq:\n",
    "            seq_str = f\"{seq:02d}\"\n",
    "            sequence_path = os.path.join(root_path, seq_str, \"logg_desc\")\n",
    "            \n",
    "            for j in range(len(data[seq_str])):\n",
    "                file_path = os.path.join(sequence_path, f\"{j:06d}.pt\")\n",
    "    \n",
    "                #if j % 5 != 0:\n",
    "                    #continue\n",
    "                \n",
    "                \n",
    "                test_feature_0 = torch.load(file_path).to(torch.float32)  # Force float32 \n",
    "\n",
    "                \n",
    "                desc_path = os.path.join(root_path, \"22\", \"logg_desc\")\n",
    "                file_path = os.path.join(desc_path, f\"{num:06d}.pt\")\n",
    "                test_feature = torch.load(file_path).to(torch.float32)\n",
    "                import pdb; pdb.set_trace()\n",
    "\n",
    "                feat_dists = cdist(global_descriptor, db_seen_descriptors,metric=cfg.eval_feature_distance).reshape(-1)\n",
    "                \n",
    "                \n",
    "                num +=1\n",
    "\n",
    "                \n",
    "                \n",
    "                best_expert0, score0, prob0 = predict_expert(gate_model, test_feature_0, device)\n",
    "                best_expert, score, prob = predict_expert(gate_model, test_feature, device)\n",
    "\n",
    "                if best_expert0 != best_expert:\n",
    "                    import pdb; pdb.set_trace()\n",
    "\n",
    "                \n",
    "                print(file_path)\n",
    "                print(f\"Predicted expert: {best_expert0}, Expected expert: {int(seq_str) }, Score: {score0}, proba: {prob0} \")\n",
    "                print(f\"Predicted expert: {best_expert}, Expected expert: {int(seq_str) }, Score: {score}, proba: {prob} \")\n",
    "                seen_proba.append(prob.cpu().numpy())\n",
    "                \n",
    "                if best_expert ==  int(seq_str):\n",
    "                    hit += 1\n",
    "                    \n",
    "    print(\"correct prediction (%): \", hit / num)\n",
    "    print(\"average proba: \", np.mean(seen_proba) )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
