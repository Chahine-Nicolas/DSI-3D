{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f935e76-d304-407d-b92b-8e5e53b40cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import torch\n",
    "import math\n",
    "#from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5eb91fa8-0df4-45f6-9c3f-c939fdefb0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################\n",
    "# Load poses\n",
    "#####################################################################################\n",
    "\n",
    "ch = logging.StreamHandler(sys.stdout)\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "logging.basicConfig(format='%(asctime)s %(message)s',\n",
    "                    datefmt='%m/%d %H:%M:%S',\n",
    "                    handlers=[ch])\n",
    "logging.basicConfig(level=logging.INFO, format=\"\")\n",
    "\n",
    "def _pad_tensors_to_max_len( tensor, max_length,tokenizer):\n",
    "    # If PAD token is not defined at least EOS token has to be defined\n",
    "    pad_token_id = (\n",
    "        tokenizer.pad_token_id if tokenizer.pad_token_id is not None else tokenizer.eos_token_id\n",
    "    )\n",
    "    tensor[tensor == -100] = tokenizer.pad_token_id\n",
    "    padded_tensor = pad_token_id * torch.ones(\n",
    "        (tensor.shape[0], max_length), dtype=tensor.dtype, device=tensor.device\n",
    "    )\n",
    "    padded_tensor[:, : tensor.shape[-1]] = tensor\n",
    "    return padded_tensor\n",
    "\n",
    "\n",
    "def transfrom_cam2velo(Tcam):\n",
    "    R = np.array([7.533745e-03, -9.999714e-01, -6.166020e-04, 1.480249e-02, 7.280733e-04,\n",
    "                  -9.998902e-01, 9.998621e-01, 7.523790e-03, 1.480755e-02\n",
    "                  ]).reshape(3, 3)\n",
    "    t = np.array([-4.069766e-03, -7.631618e-02, -2.717806e-01]).reshape(3, 1)\n",
    "    cam2velo = np.vstack((np.hstack([R, t]), [0, 0, 0, 1]))\n",
    "\n",
    "    return Tcam @ cam2velo\n",
    "\n",
    "\n",
    "def load_poses_from_txt(file_name):\n",
    "    \"\"\"\n",
    "    Modified function from: https://github.com/Huangying-Zhan/kitti-odom-eval/blob/master/kitti_odometry.py\n",
    "    \"\"\"\n",
    "    f = open(file_name, 'r')\n",
    "    s = f.readlines()\n",
    "    f.close()\n",
    "    transforms = {}\n",
    "    positions = []\n",
    "    for cnt, line in enumerate(s):\n",
    "        P = np.eye(4)\n",
    "        line_split = [float(i) for i in line.split(\" \") if i != \"\"]\n",
    "        withIdx = len(line_split) == 13\n",
    "        for row in range(3):\n",
    "            for col in range(4):\n",
    "                P[row, col] = line_split[row*4 + col + withIdx]\n",
    "        if withIdx:\n",
    "            frame_idx = line_split[0]\n",
    "        else:\n",
    "            frame_idx = cnt\n",
    "        transforms[frame_idx] = transfrom_cam2velo(P)\n",
    "        positions.append([P[0, 3], P[2, 3], P[1, 3]])\n",
    "    return transforms, np.asarray(positions)\n",
    "\n",
    "\n",
    "#####################################################################################\n",
    "# Load timestamps\n",
    "#####################################################################################\n",
    "\n",
    "\n",
    "def load_timestamps(file_name):\n",
    "    # file_name = data_dir + '/times.txt'\n",
    "    file1 = open(file_name, 'r+')\n",
    "    stimes_list = file1.readlines()\n",
    "    s_exp_list = np.asarray([float(t[-4:-1]) for t in stimes_list])\n",
    "    times_list = np.asarray([float(t[:-2]) for t in stimes_list])\n",
    "    times_listn = [times_list[t] * (10**(s_exp_list[t]))\n",
    "                   for t in range(len(times_list))]\n",
    "    file1.close()\n",
    "    return times_listn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9068abf6-0fb9-4025-9c98-708718afdf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_seq = 0\n",
    "log3dnet_dir='/lustre/fswork/projects/rech/dki/ujo91el/code/these_place_reco/LoGG3D-Net/'\n",
    "revisit_criteria=3\n",
    "not_revisit_criteria=20\n",
    "skip_time=30\n",
    "revisit_json_file = 'is_revisit_D-{}_T-{}.json'.format(\n",
    "int(revisit_criteria), int(skip_time))\n",
    "cd_thresh_min=0.001\n",
    "cd_thresh_max=5\n",
    "num_thresholds=1000\n",
    "num_beams = 10\n",
    "## ==== Kitti =====\n",
    "kitti_dir= os.getenv('WORK') + '/datas/datasets/'\n",
    "eval_seq = '%02d' % eval_seq\n",
    "sequence_path = kitti_dir + 'sequences/' + eval_seq + '/'\n",
    "_, positions_database = load_poses_from_txt(sequence_path + 'poses.txt')\n",
    "\n",
    "min_bbox = np.min(positions_database,0) \n",
    "positions_database = positions_database - min_bbox\n",
    "\n",
    "timestamps = load_timestamps(sequence_path + 'times.txt')\n",
    "revisit_json_dir = os.path.join(os.path.dirname(__file__), '/config/kitti_tuples/')\n",
    "revisit_json = json.load(open(log3dnet_dir + revisit_json_dir + revisit_json_file, \"r\"))\n",
    "is_revisit_list = revisit_json[eval_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ec5297a-d96a-4a1a-a222-46ffa2ac44f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23201"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = 0\n",
    "for i in range (len(revisit_json)):\n",
    "    c += len(revisit_json['%02d' % i])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5c74313-2b22-4e0e-857e-41e600cacdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "revisit_criteria = 3\n",
    "revisit_criteria_f = 20\n",
    "skip_time = 0\n",
    "tuple_dir = \"/lustre/fsn1/worksf/projects/rech/dki/ujo91el/datas/datasets/sequences/00/\"\n",
    "\n",
    "kitti_3m_json = 'positive_sequence_D-{}_T-{}.json'.format(int(revisit_criteria), int(skip_time))\n",
    "kitti_20m_json = 'positive_sequence_D-{}_T-{}.json'.format(int(revisit_criteria_f), int(skip_time))\n",
    "    \n",
    "dict_3m = json.load(open(tuple_dir + kitti_3m_json, \"r\"))\n",
    "dict_20m = json.load(open(tuple_dir + kitti_20m_json, \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b4e3a54b-8fb0-4fea-a90a-c37fa724e441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dict_3m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd98dcfd-b21a-4a6b-8ddb-0de2c1915d54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sandbox",
   "language": "python",
   "name": "sandbox"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
